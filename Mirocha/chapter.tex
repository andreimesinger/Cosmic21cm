\input{Mirocha/macros.tex}

\chapter{Astrophysics from the 21-cm background}

\begin{bf}
  \author{Jordan Mirocha}\\
\\
\end{bf}

The goal of this chapter is to describe the astrophysics encoded by the 21-cm background. We will begin in \S\ref{sec:RT} with a general introduction to radiative transfer and ionization chemistry in gas of primordial composition. Then, in \S\ref{sec:xi_Tk_Ja}, we will introduce techniques used to model the the UV and X-ray backgrounds that drive re-ionization and re-heating of the intergalactic medium. In \S\ref{sec:sources}, we will provide a review of the most plausible sources of ionization and heating in the early Universe, while in \S\ref{sec:predictions}, we will summarize the status of current 21-cm predictions and highlight the modeling tools available today.



%Figures 
%\begin{itemize}
%	\item Picture of reionization simulation.
%	\item Schematic of ray tracing
%	\item Show 1-D profiles to build intuition?
%	\item Show mean ionization and temperature histories from published work, defer on details of modeling assumptions to later sections.
%	\item Stellar spectra
%	\item XRB spectra 
%	\item Empirical constraints on $L_X$-SFR.
%\end{itemize}
%
%
%Here's my approach:
%\begin{itemize}
%	\item Talk about how 21-cm traces ionization and heating. Outline generic non-Eq chemistry setup and how one would do this in ``all its glory.''
%	\item Motivate separation of ionization and heating (mean free path), and how that allows more approximate techniques and useful conceptual framework. Outline those approximate techniques.
%	\item Turn to the sources. We've discussed how to model ionization and heating but not what the source terms are. Focus on evolution of individual sources and source populations (i.e., frequency bit then redshift/R bit)
%	\item Put it all together: basic predictions. Intuition for timing of different features in global signal and power spectrum, prospects for breaking degeneracies between different sources/parameters. Discussion of available tools, differences, progress? Lump in with previous section.
%\end{itemize}


%%%
%% Ionization, thermal, and Ly-a histories
%%%
\section{Properties of the High-$z$ Intergalactic Medium} \label{sec:RT}
In this section we provide a general introduction to the intergalactic medium (IGM) and how its properties are expected to evolve with time. We will start with a brief recap of the 21-cm brightness temperature (\ref{sec:dTb}), then turn our attention to its primary dependencies, the ionization state and temperature of the IGM, and the radiative processes relevant to their evolution on scales large and small (\S\ref{sec:ioniz_heating}). Readers familiar with the basic physics may skip ahead to \S\ref{sec:techniques}, in which we focus specifically on how this physics is captured in 21-cm modeling codes.

% T_21
\subsection{The brightness temperature} \label{sec:dTb}
The differential brightness temperature\footnote{Can replace this first sub-section with pointers to Chapter 1 to avoid redundancy.} of a patch of the IGM at redshift $z$ and position $\mathbf{x}$ is given by\footnote{Refer back to Chapter 1 for a more detailed introduction.} 
\begin{equation}
    \delta T_b(z, \mathbf{x}) \simeq 27 (1 + \boldmath{\delta}) (1 - \mathbf{x_i}) \left(\frac{\Omega_{b,0} h^2}{0.023} \right) \left(\frac{0.15}{\Omega_{m,0} h^2} \frac{1 + z}{10} \right)^{1/2} \left(1 - \frac{T_R}{\mathbf{T_S}} \right) , \label{eq:dTb}
\end{equation}
where $\mathbf{\delta}$ is the baryonic overdensity relative to the cosmic mean, $x_i$ is the ionized fraction, $T_R$ is the radiation background temperature (generally the CMB, $T_R = T_{\gamma}$), and
\begin{equation}
    \mathbf{T_S}^{-1} \approx \frac{T_R^{-1} + \mathbf{x_c} \mathbf{T_K}^{-1} + \mathbf{x_{\alpha}} \mathbf{T_{\alpha}}^{-1}}{1 + \mathbf{x_c} + \mathbf{x_{\alpha}}} . \label{eq:Ts}
\end{equation}
is the spin temperature, which quantifies the level populations in the ground state of the hydrogen atom, and itself depends on the kinetic temperature, $T_K$, and ``colour temperature'' of the Lyman-$\alpha$ radiation background, $T_{\alpha}$. Because the IGM is optically thick to Ly-$\alpha$ photons, the approximation $T_K \approx T_{\alpha}$ is generally very accurate.

The collisional coupling coefficients, $x_c$, themselves depend on the gas density, ionization state, and temperature, and were computed as a function of temperature in \cite{Zygelman2005}. The radiative coupling coefficient, $x_{\alpha}$, depends on the Ly-$\alpha$ intensity, $J_{\alpha}$, via
\begin{equation}
    x_{\alpha} = \frac{S_{\alpha}}{1+z} \frac{\hat{J}_{\alpha}}{{J}_{\alpha,0}} \label{eq:xalpha}
\end{equation}
where
\begin{equation}
    J_{\alpha,0} \equiv \frac{16\pi^2 T_{\star} e^2 f_{\alpha}}{27 A_{10} T_{\gamma,0} m_e c} . \label{eq:Jnorm}
\end{equation}
$\hat{J}_{\alpha}$ is the angle-averaged intensity of Ly-$\alpha$ photons in
units of $\intensityunitsnumber$, $S_{\alpha}$ is a correction factor that
accounts for variations in the background intensity near line-center
\cite{Chen2004,FurlanettoPritchard2006,Hirata2006}, $m_e$ and $e$ are the
electron mass and charge, respectively, $f_{\alpha}$ is the $\Lya$ oscillator
strength, $T_{\gamma,0}$ is the CMB temperature today, and $A_{10}$ is the Einstein A coefficient for the 21-cm transition.

A more detailed introduction to collisional and radiative coupling can be found in Chapter 1. For the purposes of this chapter, the key takeaway from Equations \ref{eq:dTb}-\ref{eq:xalpha} is simply that the 21-cm background probes the ionization field, kinetic temperature field, and $\Lya$ background intensity. We quickly review the basics of non-equilibrium ionization chemistry in the next sub-section (\S\ref{eq:ioniz_heating}) before moving on to techniques used to model these properties of the IGM in \S\ref{sec:techniques}.


% Global signal
%\subsubsection{The ``global'' 21-cm signal}
%On very large scales...
%\begin{align}
%    \delta T_b \simeq 27 (1 - \mathbf{x_i}) \left(\frac{\Omega_{b,0} h^2}{0.023} \right) \left(\frac{0.15}{\Omega_{m,0} h^2} \frac{1 + z}{10} \right)^{1/2} \left(1 - \frac{T_R}{T_S} \right) , \label{eq:dTb}
%\end{align}
%
%Many experiments are targeting this signal. For this reason, modeling efforts for the global signal often take an approximate approach. Under the assumption that fluctuations in $\delta$, $x_i$, and $T_S$ are uncorrelated, the volume-averaged differential brightness temperature is simply related to the volume-averaged density, ionization fraction, and spin temperature. Averaging over large volumes means $\delta \approx 0$, and while in general these fields \textit{will} be correlated, {\color{red} the effects are likely minor: cite that one paper that Xueli Chen is on.}
%
%
%In the next three sections, we walk through the main epochs of evolution relevant to the 21-cm background, starting with reionization, and working our way backwards in time to first light. As in this section, boldfaced symbols refer to variables with an implicit spatial dependence, while regularly typset symbols refer to the spatial average. {\color{red} is this too tedious?}
%
%Talk here about how in numerical simulations we would just do radiative transfer so there's no need to break up all these things. But, RT is expensive, so in practice most models (at least those used for inference) make approximations, and it is very convenient to consider

%%
% RT background?
%%
\subsection{Basics of Non-Equilibrium Ionization Chemistry} \label{sec:ioniz_heating}
As described in the previous section, the 21-cm brightness temperature of a patch of the IGM depends on the ionization and thermal state of the gas, as well as the incident Ly-$\alpha$ intensity\footnote{Note that Ly-$\alpha$ photons can transfer energy to the gas though we omit this dependence from the current discussion (see \S1).}. The evolution of the ionization and temperature are coupled and so must be evolved self-consistently. The number density of hydrogen and helium ions {\color{red} in a static medium} can be written as the following set of coupled differential equations\footnote{{\color{red} Gabriel Altay pointed out a typo in my He equations many years ago...make sure that's fixed.}}:
\begin{align}
    \frac{d \nHII}{dt} & = (\ionHI + \ionsecHI + \ioncollHI \nel) \nHI - \recHII \nel \nHII   \label{eq:HIIRateEquation} \\
    \frac{d \nHeII}{dt} & = (\ionHeI + \ionsecHeI + \ioncollHeI \nel) \nHeI \nonumber + \recHeIII \nel \nHeIII  - (\ioncollHeII + \recHeII + \xiHeII) \nel \nHeII \\ & - (\ionHeII + \ionsecHeII) \nHeII \label{eq:HeIIRateEquation} \\ 
    \frac{d \nHeIII}{dt} & = (\ionHeII + \ionsecHeII + \ioncollHeII \nel) \nHeII  - \recHeIII \nel \nHeIII . \label{eq:HeIIIRateEquation} .
\end{align}
Each of these equations represents the balance between ionizations of species
\HI, \HeI, and \HeII, and recombinations of \HII, \HeII, and
\HeIII. Associating the index $i$ with absorbing species, $i = $\HI, \HeI,
\HeII, and the index $i^{\prime}$ with ions, $i^{\prime} = $\HII, \HeII,
\HeIII, we define $\Gamma_i$ as the photo-ionization rate coefficient,
$\gamma_i$ as the rate coefficient for ionization by photo-electrons \cite[e.g.,][]{Shull1985,Furlanetto2010}, $\alpha_{i^{\prime}}$
($\xi_{i^{\prime}}$) as the case-B (dielectric) recombination rate
coefficients, $\beta_i$ as the collisional ionization rate coefficients, and
$\nel = \nHII + \nHeII + 2\nHeIII$ as the number density of electrons.

While the coefficients $\alpha$, $\beta$, and $xi$ only depend on the gas temperature, the photo- and secondary-ionization coefficients, $\Gamma$ and $\gamma$, depend on input from astrophysical sources and thus constitute the bulk of the challenge for theoretical models. We will revisit these coefficients in more detail momentarily.

The final equation necessary in a primordial chemical network is that governing the kinetic temperature evolution, which we can write as a sum of various heating and cooling processes, i.e.,
\begin{align}
    \frac{3}{2}\frac{d}{dt}\left(\frac{\kB T_k \ntot}{\mu}\right) & = \fheat  \sum_i n_i \Lambda_i - \sum_i \zeta_i \nel n_i - \sum_{i^{\prime}} \eta_{i^{\prime}} \nel n_{i^{\prime}} \nonumber \\ & - \sum_i \psi_i \nel n_i - \cooldielHeII \nel \nHeII \label{eq:TemperatureEvolution} .
\end{align}
Here, $\Lambda_i$ is the photo-electric heating rate coefficient (due to
electrons previously bound to species $i$), $\cooldielHeII$ is the dielectric
recombination cooling coefficient, and $\zeta_i$, $\eta_{i^{\prime}}$, and
$\psi_i$ are the collisional ionization, recombination, and collisional
excitation cooling coefficients, respectively, where primed indices
$i^{\prime}$ indicate ions $\HII$, $\HeII$, and $\HeIII$, while unprimed
indices $i$ indicate neutrals $\HI$, $\HeI$, and $\HeII$. The constants in
Equation (\ref{eq:TemperatureEvolution}) are the total number density of
baryons, $\ntot = n_\mathrm{H} + n_{\mathrm{He}} + \nel$, the mean molecular
weight, $\mu$, Boltzmann's constant, $\kB$, and the fraction of secondary
electron energy deposited as heat, $\fheat$. Formulae to compute the values of
$\alpha_i$, $\beta_i$, $\xi_i$, $\zeta_i$, $\eta_{i^{\prime}}$, $\psi_i$, and
$\cooldielHeII$, are compiled in, e.g., \cite{Fukugita1994}, {\color{red} who
else?}.

These equations do not yet explicitly take into account the cosmic expansion, which dilutes the density and adds an adiabatic cooling term to Eq. \ref{eq:TemperatureEvolution}, however these generalizations are straightforward to implement in practice, as we will show in the next section. For the duration of this chapter we will operate within this simple chemical network, ignoring, e.g., molecular species like $\Htwo$ and $\mathrm{HD}$ whose cooling channels are important in primordial gases. Though an interesting topic in their own right, molecular processes reside in the ``subgrid'' component of most 21-cm models, given that they influence how, when, and where stars are able to form, but do not directly affect the bulk properties of the IGM on large scales to which 21-cm measurements are sensitive.

%%
% POINT SOURCES
%%
\subsubsection{Ionization and Heating Around Point Sources} \label{sec:smallscales}
In order to build intuition for the progression of ionization and heating in the IGM it is instructive to consider the impact of a single point source of UV and X-ray photons on its surroundings. Many early works focused on such 1-D radiative transfer problems, and many have subsequently been implemented in full cosmological calculations ({\color{red} citations}). In principle, this is the ideal way to simulation reionization -- iterating over all sources in a cosmological volume and for each one applying 1-D radiative transfer techniques over the surrounding $4\pi$ steradians. In practice, such approaches are computationally expensive, and while they provide detailed predictions ({\color{red} citations}), more approximate techniques are required to survey the parameter space and perform inference ({\color{red} citations}).

{\color{red} Write a 1-D radiative transfer equation here!}

In an idealized 1-D geometry, i.e., one in which the source emits isotropically and the surrounding medium is spherically symmetric, the rate coefficients for ionization and heating take the following form:
\begin{align}
    \Gamma_i & = A_i \int_{\nu_i}^{\infty} I_{\nu} e^{-\tau_{\nu}} \left(1 - e^{-\Delta \tau_{i,\nu}}\right) \frac{d\nu}{h\nu} \label{eq:PhotoIonizationRate} \\
    \gamma_{ij} & = A_j \int_{\nu_j}^{\infty} \left(\frac{\nu - \nu_j}{\nu_i}\right) I_{\nu} e^{-\tau_{\nu}} \left(1 - e^{-\Delta \tau_{j,\nu}}\right) \frac{d\nu}{h\nu} \label{eq:SecondaryIonizationRate} \\
    \Lambda_i & = A_i \int_{\nu_i}^{\infty} (\nu - \nu_i) I_{\nu} e^{-\tau_{\nu}} \left(1 - e^{-\Delta \tau_{i,\nu}}\right) \frac{d\nu}{\nu} , \label{eq:HeatingRate} .
\end{align}
The normalization constant in each expression is defined as $A_i \equiv L_{\mathrm{bol}}/n_i V_{\sh}(r)$, where $V_{\sh}$ is the volume of a shell in this 1-D grid of concentric spherical shells, each having thickness $\Delta r$ and volume $V_{\sh}(r) = 4 \pi [(r + \Delta r)^3 - r^3] / 3$, where $r$ is the distance between the origin and the inner interface of each shell. We denote the ionization threshold energy for species $i$ as $h\nu_i$. $I_{\nu}$ represents the SED of radiation sources, and satisfies $\int_{\nu} I_{\nu} d\nu = 1$, such that $L_{\mathrm{bol}} I_{\nu} = L_{\nu}$. Note that the total secondary ionization rate for a given species is the sum of ionizations due to the secondary electrons from all species, i.e., $\gamma_i = \fion \sum_j \gamma_{ij} n_j / n_i$.

These expressions preserve photon number by inferring the number of photo-ionizations of species $i$ in a shell from the radiation incident upon it and its optical depth \cite[e.g.,][]{Abel1999},
\begin{equation}
    \Delta \tau_{i,\nu} = n_i \sigma_{i,\nu} \Delta r .
\end{equation}    
This quantity is not to be confused with the total optical depth between source and shell, $\tau_{\nu} = \tau_{\nu}(r)$, which sets the incident radiation field upon each shell, i.e.,
\begin{align}
    \tau_{\nu}(r) & = \sum_i \int_0^r \sigma_{i,\nu} n_i(r^{\prime}) dr^{\prime} \nonumber \\
                  & = \sum_i \sigma_{i,\nu} \ncol(r) \label{eq:OpticalDepth}
\end{align}
where $\ncol$ is the column density of species $i$ at distance $r$ from the
source. 

In words, Equations \ref{eq:PhotoIonizationRate}-\ref{eq:HeatingRate} are propagating photons from a source at the origin, with bolometric luminosity $L_{\mathrm{bol}}$, and tracking the attenuation suffered between the source and some volume element of interest at radius $r$, $e^{-\tau}$, and the attenuation within that volume element, $\Delta \tau$, which results in ionization and heating. In each case, we integrate over the contribution from photons at all frequencies above the ionization threshold, additionally modifying the integrands for $\gamma_{ij}$ and $\Lambda_i$ with $(\nu - \nu_i)$-like factors to account for the fact that both the number of photo-electrons (proportional to $(\nu - \nu_j) / \nu_i$) and their energy (proportional to $\nu - \nu_i$) that determine the extent of secondary ionization and photo-electric heating. {\color{red} Forgot to put the factors $f_{\mathrm{heat}}$ and $f_{\mathrm{ion}}$ in above equations.}

Equations \ref{eq:PhotoIonizationRate}-\ref{eq:HeatingRate} can be solved once a source luminosity, $L_{\mathrm{bol}}$, spectral shape, $I_{\nu}$, and density profile of the surrounding medium, $n(r)$, have been specified. In practice, to avoid performing these integrals on each step of an ODE solver (for Eqs. \ref{eq:eq:HIIRateEquation}-\ref{eq:TemperatureEvolution}), the results can be tabulated as a function of $\tau$ or column density, $N_i$, where $\tau_{i,\nu}=\sigma_{i,\nu} N_i$ \cite{Thomas2008,Mirocha2012}.

{\color{red} Show some example results from, e.g., Thomas et al. 2008?}

{\color{red} Mention the picket fence and $\Lya$ profile around individual sources here?}

%\begin{figure}[]
%\begin{center}
%\includegraphics[width=0.5\textwidth]{Mirocha/adaptive_RT.jpeg}
%\end{center}
%\caption{This is figure 1 in chapter 1.}
%\end{figure}
%



%%
% Metagalactic background
%%
\subsubsection{Ionization and Heating on Large Scales} \label{sec:largescales}
While the procedure outlined in the previous section is relevant to small-scale ionization and heating, i.e., that which is driven a single (or perhaps a few) source(s) nearby, it is also instructive to consider the ionization and heating caused by a \textit{population} of sources separated by great distances. In this limit, rather than considering the luminosity of a single source at the origin of a 1-D grid, we treat the volume-averaged emissivity of sources in a large ``chunk'' of the Universe, and solve for the evolution of the mean intensity in this volume. 

The transfer equation now takes its cosmological form, i.e., 
\begin{equation}
    \left(\frac{\partial}{\partial t} - \nu H(z) \frac{\partial}{\partial \nu} \right) J_{\nu}(z) + 3 H(z) J_{\nu}(z) =  \frac{c}{4\pi} \epsilon_{\nu}(z) (1 + z)^3 - c \alpha_{\nu} J_{\nu}(z) \label{eq:rte_diffeq}
\end{equation}
where $J_{\nu}$ is the mean intensity in units of $\intensityunits$, $\nu$ is the observed frequency of a photon at redshift $z$, related to the emission frequency, $\nu^{\prime}$, of a photon emitted at redshift $z^{\prime}$ as
\begin{equation}
    \nu^{\prime} = \nu \left(\frac{1 + z^{\prime}}{1 + z}\right) , \label{eq:EmissionFrequency}
\end{equation}
$\alpha_{\nu} = n \sigma_{\nu}$ is the absorption coefficient, not to be confused with recombination rate coefficient, $\alpha_{\HII}$, and $\epsilon_{\nu}$ is the co-moving emissivity of sources.

The optical depth, $d\tau = \alpha_{\nu} ds$, experienced by a photon at redshift $z$ and emitted at $z^{\prime}$ is a sum over absorbing species,
\begin{equation}
    \overline{\tau}_{\nu}(z, z^{\prime}) = \sum_j \int_{z}^{z^{\prime}} n_j(z^{\dprime}) \sigma_{j, \nu^{\dprime}} \frac{dl}{dz^{\dprime}}dz^{\dprime} \label{eq:tau_igm}
\end{equation}
To be fully general, one must iteratively solve this and $J_{\nu}$. In practice, you can tabulate $\tau$ and it works pretty good.

The solution to Equation \ref{eq:rte_diffeq} {\color{red} assuming X, Y, and Z} is
\begin{equation}
    \hat{J}_{\nu} (z) = \frac{c}{4\pi} (1 + z)^2 \int_{z}^{z_f} \frac{\epsilon_{\nu}^{\prime}(z^{\prime})}{H(z^{\prime})} e^{-\overline{\tau}_{\nu}} dz^{\prime} . \label{eq:AngleAveragedFlux}
\end{equation}    
where $z_f$ is the ``first light redshift'' when astrophysical sources first turn on, $H$ is the Hubble parameter, and the other variables take on their usual meaning. 

With the background intensity in hand, one can solve for the rate coefficients for ionization and heating, and evolve the ionization state and temperature of the gas.  These coefficients are equivalent to those for the 1-D problem (Eqs. \ref{eq:PhotoIonizationRate}-\ref{eq:HeatingRate}), though the intensity of radiation at some distance $R$ from the source has been replaced by the mean background intensity. They are:
\begin{align}
    \Gamma_{\HI}(z) & = 4 \pi \nH(z) \int_{\nu_{\min}}^{\nu_{\max}} \hat{J}_{\nu} \sigma_{\nu,\HI} d\nu  \\
    \gamma_{\HI}(z) & = 4 \pi \sum_j n_j \int_{\nu_{\min}}^{\nu_{\max}} \fion \hat{J}_{\nu} \sigma_{\nu,j} (h\nu - h\nu_j) \frac{d\nu}{h\nu}  \\
    \epsilon_X(z) & = 4 \pi \sum_j n_j \int_{\nu_{\min}}^{\nu_{\max}} \fheat \hat{J}_{\nu}  \sigma_{\nu,j} (h\nu - h\nu_j) d\nu
\end{align}
{\color{red} Note similarities between these equations and the 1-D example in previous section.}


{\color{red} Reality exists somewhere between these two extremes, hence, the next section.}

%%%
%% EVOLUTION EQUATIONS. I. Ionization
%%%
\section{Techniques for Modeling the IGM} \label{sec:techniques}
In the previous section we introduced the basics of ionization chemistry and radiative transfer in a primordial medium, and explored extreme limits on very small and very large scales. These limits bracket the range of possibilities for volume elements, which ``see'' radiation from a single (or few) source(s) nearby or the combined radiative output of many sources at cosmological distincances. {\color{red} Reality is often somewhere between.} The mean free path of photons in a hydroge-only medium is \cite[e.g.,][]{McQuinn2012}
\begin{equation}
	\lambda_{\HI} \approx 7 \xHI^{-1} \left(\frac{h\nu}{200 \ \mathrm{eV}} \right)^{2.6} \left(\frac{1+z}{10} \right)^{-2} \ \mathrm{cMpc} ,
\end{equation}
i.e., mean-free paths for UV photons with $h\nu < 0.1 keV$ (or so) are very short. Because the mean free paths of UV photons are short, the IGM is divided roughly into two different phases: (i) a fully-ionized phase composed of ``bubbles,'' which grow around UV sources, and (ii) a ``bulk IGM'' phase outside bubbles in which ionization and heating is dominated by X-rays. The boundaries between these two phases can become fuzzy if reionization is driven by sources with hard spectra. However, even in such cases, the two-phase picture is a useful conceptual framework for understanding evolution in the 21-cm background, and provides a basis for approximations to the radiative transfer that have enabled the development of more efficient approaches to modeling the 21-cm background. 

In this section, we describe the evolution of the ionization and temperature fields in this two-zone framework, in each case focusing first on the volume-averaged evolution relevant to the global 21-cm signal, and then the spatial structure relevant for 21-cm fluctuations. We will revisit extensions of the two-phase approximation in later sections.

Note that for now, we will not specify the properties of UV and X-ray sources, but instead fold their properties into a single time-, frequency-, and position-dependent emissivity, $\epsilon = \epsilon_{\nu}(z,R)$. Models for $\epsilon$ will be put forth in \S\ref{sec:sources} and \S\ref{sec:sfrd}, from which 21-cm predictions will follow in \S\ref{sec:predictions}. 

%Hydrogen atoms can be ionized by photons with energies $h\nu > 13.6$ eV. The bound-free cross-section for interaction between photons and hydrogen atoms in the ground state is given approximately by\footnote{See \cite{Verner1996} for more detailed fits to the cross section as a function of photon energy.}
%\begin{equation}
%	\sigma_{\HI} \simeq 6 \times 10^{18} \left(\frac{h\nu}{13.6 \ \mathrm{eV}} \right)^{-3} \ \mathrm{cm}^{-2} . \label{eq:xsec}
%\end{equation}	
%In a hydrogen-only medium, the mean free path is (e.g., \cite{McQuinn2012})
%\begin{equation}
%	l \equiv \frac{1}{n_{\HI} \sigma_{\HI}} \simeq 100 \ \mathrm{kpc} \left( \frac{0.0486}{\Omega_{b,0} h^2} \right) \left(\frac{0.9187}{1-y}\right) \left( \frac{E}{13.6 \mathrm{eV}} \right)^3 \left(\frac{10}{1+z} \right)^3 \label{eq:mfp}
%\end{equation}


%%
% DENSITY
%%
\subsection{The Density Field}
{\color{red} Do we want to delve into this here? Discuss Dex-M, etc.}

%%
% IONIZATION FIELD
%%
\subsection{The Ionization Field}

% Global ionization evolution
\subsubsection{Global Evolution} \label{sec:ionization_global}
In the two phase approximation of the IGM, the volume-averaged ionized fraction is a weighted average between the fully-ionized phase, with volume filling fraction $\QHII$, and the (likely) low-level ionization in the bulk IGM phase, characterized by its electron fraction, $x_e$, i.e.,
\begin{equation}
	\xibar = \QHII + (1 - \QHII) x_e
\end{equation}
{\color{red} Note that we should be more careful about $x_e$ and $\xHII$. the former is important for collisional coupling, the latter for $\xibar$} 

In the limit of neglible ionization in the bulk IGM phase, $\xibar \approx \QHII$, we recover the standard ionization balance equation for reionization (e.g., Madau et al., others),
\begin{equation}
	\frac{d \QHII}{dt} = \nHI \Gamma_{\HI} - n_e \nHII \alpha_{\HII} \label{eq:ion_balance}
\end{equation}
where we have written the rate coefficient for photo-ionization generically as {\color{red} the ionization photon production rate}...We have also neglected collisional ionization and ionization by hot photo-electrons, though such effects could be absorbed into $\Gamma_{\HI}$\footnote{Secondary ionization is generally unimportant in HII regions since stars do not emit much above 1 Rydberg. As a result, photo-electrons are incapable of causing further ionization, and instead deposit most of their energy in heat or collisioanl excitation.}.

%The recombination coefficient is a function of temperature,
%\begin{equation}
%	\alpha_{\HII} = 2.6 \times 10^{-13} \left(\frac{T_K}{10^4 \ \mathrm{K}} \right)^{-0.8}
%\end{equation}

Note: unlike the post-EoR Universe, we never really care about the UV background because it only exists inside bubbles. Up until late times, the background intensity in bubbles cannot reasonably be considered a useful global metric since it only traces galaxies relatively nearby (i.e., in that bubble).

Talk about CMB optical depth here and maybe LAEs.
\begin{equation}
	\tau_e = \int_0^{R_{\mathrm{ls}}} dl n_e \sigma_T
\end{equation}
where $\sigma_T = 6.65 \times 10^{-25} \ \mathrm{cm}^{-2}$ is the Thomson cross section.

In the limit of a completely neutral bulk IGM, this reduces to...


Sometimes people treat $\tau_e$ like a free parameter. 

Outline current constraints?


% Spatial structure of ionization field
\subsubsection{Spatial Structure} \label{sec:ionization_local}
While the evolution of the average ionized fraction contains a wealth of information about the properties of UV (and perhaps X-ray) sources in the early Universe, fluctuations in the ionization field contain much more information. Indeed, the patchy ``swiss cheese'' structure generic to UV-driven reionization scenarios provided the initial impetus to study reionization via 21-cm interferometry \cite{Madau1997}.

If computational resources were no issue, radiative transfer simulations would be the ideal tool to approach this problem for reasons that will be apparent momentarily. However, once again, the two-phase approximation opens the door to a simple statistical treatment of fluctuations in the ionization field. Given that 21-cm fluctuation efforts are geared largely toward measuring the 21-cm power spectrum, here we restrict our discussion to the ionization power spectrum, which forms a part of the 21-cm power spectrum that we will describe in more detail in subsequent sections.

The power spectrum of the ionization field is simply the Fourier transform of its two-point correlation function, which we can write as
\begin{equation}
	\xi \equiv \langle x_i x_i^{\prime} \rangle - \langle x_i \rangle^2 ,
\end{equation}
where $x_i$ is the ionized fraction at a point $\mathbf{p}$, while $x_i^{\prime}$ is the ionized fraction at a point $\mathbf{p}^{\prime} = \mathbf{p} + \mathbf{R}$, i.e., a different point a distance $\mathbf{R}$ from the first point. The expectation value is related to the joint probability, i.e.,
\begin{equation}
	\langle x_i \xipr \rangle = \int dx_i \int d\xipr x_i \xipr f(x_i, \xipr) .
\end{equation}
If we now assume that ionization in the ``bulk'' IGM is negligible, $x_i$ is a binary field, taking on values of 0 or 1 exclusively. In this limit, the expectation value is simply
\begin{equation}
	\langle x_i \xipr \rangle = f(x_i=1, \xipr=1) \equiv P_{ii} ,
\end{equation}
i.e., $\langle x_i \xipr \rangle$ is equivalent to the probability that both points are ionized. 

Now, to model the probability of ionization we first assume that the ionizatoin field is composed of discrete, spherical bubbles, with size distribution $dn/dR$. Then, taking inspiration from the halo model \cite{Cooray2002}, we can write $P_{ii}$ as the sum of two terms,
\begin{equation}
	P_{ii} = P_{ii,1b} + P_{ii,2b}
\end{equation}
where the first term encodes the configuration in which both points are within a single bubble (hence the ``1b'' subscript), while the second term is the probability that points are in different bubbles. 

Two points separated by $r_{12}$ can be ionized by the same bubble so long as the diameter of the bubble is the distance between the points or greater. For bubbles bigger than the absolute minimum ($r_{12}$), there is an ``overlap region,'' with volume $\IV$, in which a bubble of mass $m$ can ionize both points.

If $p_1$ is ionized, then the probability that $p_2$ is ionized by the same source will be equal to the probability that a sufficiently large source, with mass $m$, resides within the overlap region of $p_1$ and $p_2$, whose volume depends on their separation. The overlap region, $V_o$, is thus given by the area of intersection between two spheres, assumed here to have the same radius $R$, placed a distance $r_{12}$ apart,
\begin{equation}
  \IV = 
  \begin{cases}
    \frac{4}{3}\pi R(m)^2 - \pi r_{12} \left[R(m)^2 - \frac{r_{12}^2}{12} \right] & r_{12} < 2 R(m) \\
    0 & r_{12} > 2 R(m)
  \end{cases}
  \label{eq:V_overlap}
\end{equation}
We will denote the probability that two points are ionized by a source of mass $m$ as $P\left[m,\IV(m,r_{12})\right]$.

This argument results in an infinite sum over probabilities, with each successive terms corresponding to the probability that a point is ionized by increasingly large bubbles (accounting for the probability that smaller bubbles could \textit{not} ionize both points, i.e., the product of the negation of all previous terms), i.e.,
\begin{align}
    P_{ii,1} (r_{12}) & = P\left[m_1,\IV(m_1,r_{12})\right] \nonumber \\
    & + (1 - P\left[m_1,\IV(m_1,r_{12})\right]) P\left[m_2,\IV(m_2,r_{12})\right] + ... \nonumber \\
    & = P_1 + (1 - P_1) P_2 + (1 - P_1)(1 - P_2) P_3 + ... \nonumber \\
    & = P_1 + (P_2 - P_1 P_2) + (P_3 - P_3 P_1 - P_3 P_2 + P_1 P_2 P_3) + ... \nonumber \\
    & = 1 - P_1 P_2 - (P_1 P_3 - P_2 P_3 + P_1 P_2 P_3) + ... \nonumber \\
    & = 1 - (1 - P_1) (1  - P_2) (1 - P_3) ... \nonumber  \\
    & = 1 - \Pi_i (1 - P_i) \nonumber \\
    & = 1 - \exp \left[ \sum_i \log(1 - P_i) \right]
\end{align}
To compute the probabilities, we need only the abundance of sources as a function of their mass, which we will leave as a general quantity $n(m)$, for now, and the overlap volume, i.e.,
\begin{equation}
    P\left[m_1,\IV(m_1,r_{12})\right] = n(m_1) \IV(m_1,r_{12})
\end{equation}
Now, the last step is to realize that $P_i = 1 - \exp\left[-n_i V_i] \right]$. This follows from a Poissonian argument, in which the probability is
\begin{equation}
    P_i = \frac{\lambda^N e^{-\lambda}}{N!}
\end{equation}
But, we don't care which source does the ionizing, so we should just compute the probability that there's \textit{not} a source in the volume, and subtract that from one to obtain the probability that there's \textit{any kind of} source in the volume. We know the mean number of bubbles, so we can make a Poissonian argument with $N=0$ to determine this probability, i.e.,
\begin{equation}
    P(N \geq 1) = 1 - P(N = 0) = 1 - e^{-\lambda} \label{eq:P1src}
\end{equation}
So, the probability that two points like in a single ionized bubble is
\begin{equation}
    P_{ii,1} (r_{12}) = 1 - \exp \left[ -\sum_i n(m_i) \IV(m_i,r_{12}) \right]
\end{equation}
The other possibility is that two points are members of two different bubbles, which we denote with the probability $P_{ii,2}$. The probability of this occurring is the probability that a single source \textit{cannot} ionize both points, times the probability that a source of mass $m$ is able to ionize the first point but not the second. If we visualize the overlap of two spheres, we need the second source \textit{not} to reside in the overlap region. So, we can simply replace $\IV \rightarrow V(m) - \IV$ in Equation \ref{eq:P1src}, and square it (to obtain probability of two sources). The total probability is then
\begin{align}
    \langle x \xpr \rangle & = P_{ii,1} + P_{ii,2} \nonumber \\
    & = 1 - \exp \left[- \int n(m) \IV(m,r_{12}) dm \right] \nonumber \\
    & + \exp \left[- \int n(m) \IV(m,r_{12}) dm \right] \times \left\{1 - \exp \left[- \int n(m) (V(m) - \IV(m,r_{12})) dm \right] \right\}^2
\end{align}
This is only valid if we neglect clustering of sources. In reality, if we're in the neighborhood of a bubble, there's a good chance there's another bubble nearby. So, we can replace one of the terms in curly braces with $n(m) \rightarrow n(m) (1 + \xi_{bb}(m, r_{12}))$, where $\xi_{bb}$ is the excess probability of finding a bubble of mass $m$ a distance $r_{12}$ away from another bubble. 




\cite{Furlanetto2004}. Will revisit codes in \S\ref{sec:predictions}.

\begin{equation}
	\zeta \fcoll = 1
\end{equation}


{\color{red} Talk about bubble size distribution.}

Note that this model makes potentially different predictions for $\QHII$! People have tried to remedy this photon-conservation issue, see, e.g., Paranjape \& Choudhury, others?


The core challenge in modeling these spatial fluctuations in analytic or semi-numeric frameworks is handling the overlap of otherwise spherical bubbles...


Talk about how big the typical voxel is and what the trade-offs are there.


Mention that we'll talk in more detail about tools like 21cmFAST later on.

Point out what fluctuations get us beyond mean signal!


Mention current constraints from end of reionization.


\subsubsection{Effects of Helium Reionization}
HeI and HI likely re-ionize at the same time....HeII later.

Mention correction factor $A_{\mathrm{He}}$ that one often sees in papers?

%%
% EVOLUTION EQUATIONS. II. Temperature
%%
\subsection{The (Kinetic) Temperature Field}
Energetic X-ray photons with $E > 100$ eV will be able to travel large distances due to the strong energy dependence of the bound-free cross section (see Eqs. \ref{eq:xsec}-\ref{eq:mfp}). As a result, the ionization state and temperature of gas in the ``bulk IGM'' spans a continuum of values and must be evolved in detail. 

% Mean temperature
\subsubsection{Global Evolution} \label{sec:temperature_global}
The largely binary nature of the ionization field results in models designed to describe the fractional volume of ionized gas and the size distribution of individual ionized regions. This binarity will be reflected in the temperature field as well given that ionized regions will be $\sim 10^4$ K, while the rest of the bulk IGM will generally be much cooler. However, given that the 21-cm background is insensitive to the temperature within ionized regions, in what follows the mean kinetic temperature will \textit{not} refer to a volume-averaged temperature, but rather the average temperature of gas outside fully-ionized regions. 

Modeling the temperature in the bulk of the IGM in a general case is best handled by radiative transfer simulations. However, such simulations can be even more challenging than those targeting the ionization field given that (i) the mean-free paths of relevant photons are longer, (ii) the frequency-dependence of the ionization and heating rates is important, which means multi-frequency calculations are necessary, and (iii) heating generally precedes reionization, meaning smaller halos must be resolved at earlier times. 

It is useful to consider first a case in which heating of the IGM is spatially uniform, which could occur if the sources of heating have very hard spectra. In this limit, we can consider the evolution of the average background intensity,



Show simple models a la Pritchard \& Loeb.



% Fluctuations in the temperature
\subsubsection{Spatial Structure} \label{sec:temperature_local}



Talk about Jonathan's 2007 approach, Janakee's stuff, 21cmFAST approach, progress in RT sims (hard because X-ray mfp long). Ross et al. simulations.



%%
% EVOLUTION EQUATIONS. III. Ly-a coupling
%%
\subsection{The Ly-$\alpha$ Background}
Here, we can 


\subsubsection{Global Evolution}
The $\Lya$ background intensity, which determines the strength of Wouthuysen-Field coupling \cite{Wouthuysen1952, Field1958}, requires a special solution to the cosmological radiative transfer equation (see Eq. \ref{eq:rte_diffeq}). Two effects separate this problem from the generic transfer problem outlined in the previous section: (i) the Lyman series forms a series of horizons for photons in the $10.2 < h \nu / \mathrm{eV} < 13.6$ interval, and (ii) the Ly-$\alpha$ background is sourced both by photons redshifting into the line resonance as well as those produced in cascades downward from higher $n$ transitions.

It is customary to solve the RTE in small chunks in frequency space. Within each chunk, the optical depth of the IGM is small\footnote{But for a small $H_2$ contribution, which here we neglect.}, while the edges are semi-permeable. For illustrative purposes, let us isolate the $\Lya$ background intensity sourced by photons redshifting into resonance from frequencies redward of Ly-$\beta$.


is computed analogously via
\begin{equation}
    \widehat{J}_{\alpha}(z) = \frac{c}{4\pi} (1 + z)^2 \sum_{n = 2}^{\nmax} \frecn \int_z^{z_{\max}^{(n)}} \frac{\epsilon_{\nu}^{\prime}(z^{\prime})}{H(z^{\prime})} dz^{\prime} \label{eq:LymanAlphaFlux}
\end{equation}
where $\frecn$ is the ``recycling fraction,'' that is, the fraction of photons that redshift into a Ly-$n$ resonance that ultimately cascade through the $\Lya$ resonance \cite{Pritchard2006}. We truncate the sum over Ly-$n$ levels at $n_{\max}=23$ as in \cite{Barkana2005}, and neglect absorption by intergalactic $H_2$. The upper bound of the definite integral,
\begin{equation}
    1 + z_{\max}^{(n)} = (1 + z) \frac{\left[1 - (n + 1)^{-2}\right]}{1 - n^{-2}} ,
\end{equation}
is set by the horizon of $\Lyn$ photons -- a photon redshifting through the  $\Lyn$ resonance at $z$ could only have been emitted at $z^{\prime} < z_{\max}^{(n)}$, since emission at slightly higher redshift would mean the photon redshifted through the $\text{Ly}(n+1)$ resonance.


Talk about excitation of Lyman alpha by photo-electrons.

\subsubsection{Spatial Fluctuations in the Ly-$\alpha$ background} 
Holzbauer, Barkana, who else? Ahn, picket fence stuff.



%\subsection{Overlap in Evolution}
%In the previous sections we have treated the evolution in each field as an independent process when of course, they are not. For example, the opacity of the IGM that X-rays see depends on the ionized fraction, in addition, the recombination rate depends on the clumping of gas in the IGM. Both of these show how UV and X-ray background are linked...


%%
% Heatting
%%
\subsubsection{$\Lya$ Heating}
Talk about initial papers about $\Lya$ heating, the subsequent revisions, and the revival of this concept in the last year or so.


\subsubsection{Excitation of $\Lya$ via fast photo-electrons}

%%%
%% SOURCES
%%%
\section{Spectral Properties of UV and X-ray Sources} \label{sec:sources}
In the previous section we outlined a procedure for evolving the ionization and temperature field without actually specificying the sources of ionization and heating. Instead, we used a generic emissivity, $\epsilon_{\nu}$, to encode the integrated emissions of sources at frequency $\nu$ within some region $R$, which we can write as an integral over the differential luminosity function of sources, i.e.,
\begin{equation}
	\epsilon_{\nu}(z,R) = \int_0^{\infty} dL_{\nu} \frac{dn}{dL_{\nu}} .
\end{equation}
Given the success of models which link the evolution of galaxies to the evolution of their host dark matter halos ({\color{red} citations}), it is common to rewrite the emissivity as a weighted integral over the DM halo mass function (HMF), $dn/dm$, 
\begin{equation}
	\epsilon_{\nu}(z,R) = \int_{\mmin}^{\infty} dm \frac{dn}{dm} \frac{dm}{d L_{\nu}} ,
\end{equation}
where $\mmin$ is the minimum mass of DM halos capable of hosting galaxies. Because $dn/dm$ is reasonably well-determined from large N-body simulations of structure formation ({\color{red} citations}), much of the modeling focus is on the mass-to-light ratio, $dm/dL_{\nu}$, which encodes the efficiency with which galaxies form in halos and the relative luminosities of different kinds of sources within galaxies (e.g., stars, compact objects, diffuse gas) that emit at different frequencies. 

We generally consider regions $R$ that are sufficiently large that one can assume a well-populated HMF\footnote{Note about how this may not be true...}. Simple models for the global 21-cm signal are an illustrative limiting case -- if one neglects all potential spatial structure in the source distribution and IGM properties, the mean 21-cm background probes the emissivity averaged over the \textit{entire Universe}. However, even for models targeting spatial fluctuations, we generally only consider relatively large $R \sim$ Mpc scale regions, since the ionized bubbles detectable in 21-cm maps are sourced by many galaxies (see \S\ref{sec:ionization_local}). 

The main strength of the 21-cm background as a probe of high-$z$ galaxies is now apparent: though 21-cm measurements cannot constrain the properties of individual galaxies, they can constrain the properties of \textit{all} galaxies, in aggregate, \textit{even those too faint to be detected directly}. As a result, it is common to forego detailed modeling of the mass-to-light ratio and instead model the emissivity as
\begin{equation}
	\epsilon_{\nu}(z, R) = \rho_b \fcoll(z, R) \zeta_{\nu} ,
\end{equation}
where the collapsed fraction is
\begin{equation}
	\fcoll = \rho_m^{-1} \int_{\mmin}^{\infty} dm m \frac{dn}{dm}
\end{equation}
and $\zeta_{\nu}$ is an efficiency factor that quantifies the number of photons emitted at frequency $\nu$ per baryon of collapsed mass in the Universe. It is generally modeled as
\begin{equation}
	\zeta_{\nu} = f_{\ast} N_{\nu} f_{\esc,\nu} , \label{eq:zeta}
\end{equation}
where $f_{\ast}$ is the star formation efficiency (SFE), $N_{\nu}$ is the number of photons emitted per stellar baryon at some frequency $\nu$, and $f_{\esc}$ is the fraction of those photons that escape into the IGM. One could define additional $\zeta$ factors to represent, e.g., emission from black holes or exotic particles, in which case $f_{\ast}$ and $N_{\nu}$ would be replaced by some black hole or exotic particle production efficiencies. In practice, three $\zeta$ factors are defined: $\zeta$, $\zeta_X$, and $\zeta_{\alpha}$, i.e., one efficiency factor for each radiation background of interest. A minimal model for the 21-cm background thus contains four parameters: $\mmin$, $\zeta$, $\zeta_X$, and $\zeta_{\alpha}$. 

Because the factors within $\zeta$ are degenerate with each other, at least as far as 21-cm measurements are concerned, they generally are not treated separately as free parameters. However, it is still useful to consider each individually in order to determine a fiducial value of $\zeta$ and explore deviations from the fiducial model. In addition, inclusion of ancillary measurements may eventually allow $\zeta$ to be decomposed into its consituent parts. For the remainder of this section, we focus on plausible values of $N_{\nu}$ and $f_{\esc}$, leaving a more detailed discussion of $f_{\ast}$ to \S\ref{sec:sfrd}. 


% STARS
\subsection{UV Emission from Stars}
Stellar photons are likely the dominant drivers of reionization\footnote{There is still some room for a contribution from quasars \cite[see, e.g.,][]{Madau2018}.} and the initial ``activation'' of the 21-cm background via Wouthuysen-Field coupling at $z \sim 30$. The 21-cm background is thus sensitive to the spectral characteristics of stars in the Lyman continuum and Lyman Werner bands\footnote{We use this definition here loosely. Technically, the LW band is $\sim 11.2-13.6$ eV, a range which bounds photons capable of photo-dissociating molecular hydrogen, $H_2$. The $\Lya$ background is sourced by photons in a slightly broader interval, $\sim 10.2-13.6$ eV, but it is tedious to continually indicate this distinction, and as a result, we use ``LW band'' to mean all photons capable of eventually generating $\Lya$ photons.}. It is also in principle sensitive to the spectrum of even harder He-ionizing photons, since photo-electrons generated from helium ionization can heat and ionize the gas, while HeII recombinations can result in H-ionizing photons. The 21-cm signal could in principle even constrain the rest-frame infrared spectrum of stars in the early Universe, since IR photons can feedback on star-formation at very early times through $H^-$ photo-detachment \cite{WolcottGreen2012}. In this section, we focus only on the soft UV spectrum ($E < 54.4$ eV) to which the 21-cm background is most sensitive.

The most detailed predictions for stellar spectra come from stellar population synthesis (SPS) models, which take the following approach:
\begin{itemize}
	\item Assume a model for the stellar initial mass function (IMF), $\xi(m)$, i.e., the number of relative number of stars formed in different mass bins. Commonly-adopted IMFs include Salpeter \cite{Salpeter1955}, Chabrier \cite{Chabrier2003}, Kroupa \cite{Kroupa2001}, and Scalo \cite{Scalo1998} which are all generally power-laws with indices $\sim -2.3$ , but differing in shape at the low mass end of the distribution ($M_{\ast} < 0.5 \ \Msun$ ).
	\item Assume a model for stellar evolution, i.e., how stars of different masses age and traverse the Hertzprung-Russell (HR) diagram.
	\item Assume a model for stellar atmospheres, i.e., as a function of stellar mass, age, and composition, determine the output spectrum.
\end{itemize}
With all these ingredients, one can synthesize a spectrum from a population of stars with a given age,
\begin{equation}
	L_{\nu}(t) = \int_0^t dt^{\prime} \int_{\mmin}^{\infty} dm \xi(m) l_{\nu} (m, t^{\prime}) \label{eq:Lcluster}
\end{equation}
where $l_{\nu}(m, t)$ is the specific luminosity of a star of mass $m$ and age $t$, and we have assumed that $\xi$ is normalized to the mass of the star cluster, $\int dm \xi(m) = M_{\ast}$. Equation \ref{eq:Lcluster} can be generalized to determine the spectrum of a galaxy with an arbitrary star formation history (SFH) composed of discrete bursts. {\color{red} mention poor IMF sampling? Widely used stellar synthesis codes include \textsc{starburst99} \cite{Leitherer1999}, \textsc{bpass} \cite{Eldridge2009}, FSPS, Bruzual \& Charlot...}

Generally, 21-cm models do not operate at level of SPS models because the 21-cm background is insensitive to the detailed spectra and SFHs of individual galaxies. Instead, because 21-cm measurements probe the relatively narrow intervals $10.2 < h\nu / \mathrm{eV} < 13.6$ via Wouthuysen-Field coupling and $h\nu > 13.6$ eV through the ionization field, it is common to distill the predictions of SPS models into just two numbers, $\Nion$ and $N_{\alpha}$, which integrate over age and the details of the stellar SED, i.e.,
\begin{align}
	\Nion & = m_{\ast}^{-1} \int_0^{\infty} dt^{\prime} \int_{\nuLL}^{\infty} \frac{d\nu}{h\nu} L_{\nu}(t^{\prime}) \\
	N_{\alpha} & = m_{\ast}^{-1} \int_0^{\infty} dt^{\prime} \int_{\nuLya}^{\nuLL} \frac{d\nu}{h\nu} L_{\nu}(t^{\prime}) \nonumber \\
\end{align}
where $\nuLL$ is the frequency of the Lyman limit (13.6 eV) and $\nuLya$ is the Ly-$\alpha$ frequency. The time integral is expected to be quite accurate given that UV emission is dominated by massive, short-lived stars. 

Assuming a Scalo IMF, stellar metallicity of $Z=Z_{\odot}/20$, using \textsc{starburst99} SPS model, \cite{Barkana2001} report $N_{\alpha}=9690$, further broken down into sub-intervals between each Ly-$n$ resonance, an oft-used reference value even today. {\color{red} The canonical value of $\Nion=4000$ (I think) makes the same assumptions but I can't find where this first appeared.} The general expectation is for $\Nion$ and $N_{\alpha}$ increase for more top-heavy IMF and lower metallicity, meaning these values are likely to increase for Pop~III stars ({\color{red} citations}). Similarly, binary evolution can effectively increase the lifetimes of massive stars, leading to a net gain in UV photon production \cite{Stanway2016}.

{\color{red} Note that detailed SPS may be needed to if jointly fitting 21-cm measurements and galaxy population.}

{\color{red} Summarize briefly the status of $\fesc$.}



%%%
%% BHs ETC
%%%
\subsection{X-rays from Black Holes}
Though stars themselves emit few photons at energies above the HeII-ionizing edge ($\sim 54.4$ eV), their remnants can be strong X-ray sources. While solitary remnants will be unlikely to accrete much gas from the diffuse ISM, remants in binary systems may accrete gas from their companions, either via Roche-lobe overflow or stellar winds. Such systems are known as X-ray binaries (XRBs), further categorized by the mass of the donor star: ``low-mass X-ray binaries'' (LMXBs) are those fueled by Roche-lobe overflow from a low-mass companion, while ``high-mass X-ray binaries'' (HMXBs) are fed by the winds of massive companions. XRBs exhibit a rich phenomenology of time- and frequency-dependent behavior and are thus interesting in their own right. For a review see, e.g., \cite{Remillard2006}.

In nearby star-forming galaxies, the X-ray luminosity is generally dominated by the HMXBs \cite{Gilfanov2004,Fabbiano2006,Mineo2012a}. Furthermore, the total luminosity in HMXBs scales with the star formation rate, as expected given that the donor stars in these systems are massive, short-lived stars. An oft-used result in the 21-cm literature stems from the work of \cite{Mineo2012a} (update of Gilfanov), who find
\begin{equation}
	L_X = 2.6 \times 10^{39} \left(\frac{\SFR}{M_{\odot} \ \mathrm{yr}^{-1}} \right) \ \mathrm{erg} \ \mathrm{s}^{-1} \label{eq:LxSFR_Mineo}
\end{equation}
where $L_X$ refers to the 0.5-8 keV band. This relation provides an initial guess for many 21-cm models, which add an extra factor $f_X$ to parameterize our ignorance of how this relation evolves with cosmic time. For example, \cite{Furlanetto2006} write
\begin{equation}
	L_X = 3 \times 10^{40} f_X \left(\frac{\SFR}{M_{\odot} \ \mathrm{yr}^{-1}} \right) \ \mathrm{erg} \ \mathrm{s}^{-1} , \label{eq:LxSFR_Furlanetto}
\end{equation}
which is simply Equation \ref{eq:LxSFR_Mineo} re-normalized to a broader energy range, $0.2 < h\nu/\mathrm{keV} < 3\times 10^4$, assuming a power-law spectrum with spectral index $\alpha_X=-1.5$, where $\alpha_X$ is defined by $L_E \propto E^{\alpha_X}$, with $L_E$ in energy units. 

The normalization of these empirical $L_X$-SFR relations are not entirely unexpected, at least at the order-of-magnitude level. For example, if one considers a galaxy forming stars at a constant rate, a fraction $f_{\bullet} \simeq 10^{-3}$ of stars will be massive enough ($M_{\ast} > 20 \ M_{\odot}$) to form a black hole assuming a Chabrier IMF. Of those, a fraction $\fbin$ will have binary companions, with a fraction $\fsurv$ surviving the explosion of the first star for a time $\tau$. If accretion onto these black holes occurs in an optically thin, geometrically-thin disk with radiative efficiency $\epsilon_{\bullet} = 0.1$ which obeys the Eddington limit, then a multi-color disk spectrum is appropriate and a fraction $f_{0.5-8}=0.84$ of the bolometric luminosity will originate in the 0.5-8 keV band. Finally, assuming these BHs are ``active'' for a fraction $\fact$ of the time, we can write \cite{Mirabel2011,Mirocha2018}
\begin{equation}
	L_X \sim 2 \times 10^{39} \mathrm{erg} \ \mathrm{s}^{-1} \left(\frac{\SFR}{\SFRunits} \right) \left(\frac{\epsilon_{\bullet}}{0.1}\right) \left(\frac{f_{\bullet}}{10^{-3}} \right) \left(\frac{\fbin}{0.5} \right) \left(\frac{\fsurv}{0.2} \right) \left(\frac{\tau}{20 \ \mathrm{Myr}} \right) \left(\frac{\fact}{0.1} \right) \left(\frac{f_{0.5-8}}{0.84} \right) . \label{eq:LxSFR}
\end{equation}
While several of these factors are uncertain, particularly $\fsurv$ and $\fact$, this expression provides useful guidance in setting expectations for high redshift. For example, it has long been predicted that the first generations of stars were more massive on average than stars today owing to inefficient cooling in their birth clouds. This would boost $f_{\bullet}$, and thus $L_X/\SFR$, so long as most stars are not in the pair-instability supernova (PISN) mass range, in which no remnants are expected. 

There are of course additional arguments not present in Eq. \ref{eq:LxSFR}. For example, the MCD spectrum is only a good representation of HMXB spectra in the ``high soft'' state. At other times, in the so-called ``low hard'' state, HMXB spectra are well fit by a power-law. The relative amount of time spent in each of these states is unknown. 

In addition, physical models for the $L_X$-SFR relation may invoke the metallicity as a driver of changes in the relation with time and/or galaxy (stellar) mass. As the metallicity declines, one might expect the stellar IMF to change (as outlined above), however, the winds of massive stars responsible for transferring material to BHs will also grow weaker as the opacity of their atmospheres decline. As a result, increases in $L_X$/SFR likely saturate below some critical metallicity. Observations of nearby, metal-poor dwarf galaxies support this picture, with $L_X$/SFR reaching a maximum of $\sim 10$ times the canonical relation quoted in Eq. \ref{eq:LxSFR_Mineo} \cite{Mineo2012}.


Left to discuss:
\begin{itemize}
	\item Observational limits on $L_X$/SFR from Chandra stacks.
	\item Low metallicity constraints.
	\item LMXB contamination.
	\item Validity of nearby sources as EoR analogs.
\end{itemize}


%%
% PopIII
%%
\subsubsection{Super-massive Black Holes}
{\color{red} Say a few words about plausibility, reference \cite{Tanaka2016}.}



% Hot gas
\subsection{X-rays from Shocks and Hot Gas}
While compact remnants of massive stars are likely the leading producer of X-rays in high-$z$ star-forming galaxies (see previous sub-section), the supernovae events in which these objects are formed may not be far behind. Supernovae inject a tremendous amount of energy into the surrounding medium, which then cools either via inverse Compton emission (in supernova remnants; \cite{Oh2001}) or eventually via bremsstrahling radiation (in the hot interstellar medium; ISM. Because these sources are related to the deaths of massive stars their luminosity is expected to scale with SFR, as in the case of HMXBs. Indeed, \cite{Mineo2012b} find that diffuse X-ray emission in nearby sources follows the following relation in the 0.5-2 keV band:
\begin{equation}
	L_X = 8.3 \times 10^{38} \left(\frac{\SFR}{M_{\odot} \ \mathrm{yr}^{-1}} \right) \ \mathrm{erg} \ \mathrm{s}^{-1} \label{eq:LxSFRII_Mineo}
\end{equation}
This luminosity is that from all unresolved emission, and as a result, is not expected to trace emission from the hot ISM alone. Emission from supernova remnants will also contribute to this luminosity, as will fainter, unresolved HMXBs and LMXBs. \cite{Mineo2012b} estimate that $\sim 30-40$\% of this emission may be due to unresolved point sources. 

Though the soft X-ray luminosity from hot gas appears to be subdominant to the HMXB component in nearby galaxies, there are of course uncertainties in how these relations evolve. Furthermore, the bremmstrahlung emission characteristic of hot ISM gas has a much steeper $\sim \nu^{-2.5}$ spectrum than inverse Compton ($\sim \nu^{-1}$) or XRBs ($\sim \nu^{-1}$ or $\nu^{-1.5}$), and thus may heat more efficiently (owing to $\sigma \propto \nu^{-3}$ cross section) provided soft X-rays can escape galaxies. 

Given the many unknowns regarding X-ray emission in the early Universe, 21-cm models often employ a three-parameter approach, i.e., instead of a single value of $\zeta_X$, the specific X-ray luminosity is modeled as 
\begin{equation}
	L_{X,\nu} = L_{X,0} \left(\frac{h \nu}{1 \mathrm{keV}} \right)^{\alpha_X} \exp\left[-\sigma_{\nu} \NHI \right]
\end{equation}
and the normalization, $L_{X,0}$, spectral index $\alpha_X$, and typical column density, $\NHI$, are left as free parameters. The column density is used to account for absorption by neutral hydrogen in the ISM, which hardens the intrinsic spectrum. Simulations suggest typical values of $\NHI \sim 10^{21} \ \mathrm{cm}^{-2}$ \cite{Das2017}, which is substantial enough to eliminate emission below $\sim 0.5$ keV. 

It is common to approximate this intrinsic attenuation with a piecewise model for $L_X$, i.e., 
\begin{align}
L_{X,\nu} = \left\{ \begin{array}{cc} 
                0 & h\nu < \Emin \\
                L_{X,0} \left(\frac{h \nu}{1 \mathrm{keV}} \right)^{\alpha_X} & h\nu \geq \Emin \
                \end{array} \right.
\end{align}


Note that $\NHI$ (or $\Emin$) can be degenerate with the intrinsic spectrum, e.g., the SED of HMXBs in the high-soft state exhibits a turn-over at energies $h\nu < 1$ keV, which could be mistaken for strong intrinsic absorption.


% DCBHS? 
\subsection{Cosmic Rays from Supernovae}
{\color{red} Other sources of high energy radiation have been explored in recent years though are generally found to be sub-dominant. However, surprises may be in store...}



%%%
%% Evolution of SFRD
%%%
\section{Star and BH Formation} \label{sec:sfrd}
In the previous section we highlighted the spectral properties of the first luminous sources without specifying a model for how, when, and where they are expected to form. Here, we outline commonly-used approaches for modeling the redshift and spatial distribution of sources at high redshift, starting with the very first stars (\S\ref{sec:firststars}), proceeding through the transition to normal star formation (\S\ref{sec:PopIII2PopII}) and finally, the evolution of ``normal'' Pop~II galaxies (\S\ref{sec:galaxies}). 

{\color{red} We're basically modeling $f_{\ast}$ and $\mmin$ in this section.}


%%
% PopIII stars
%%
\subsection{First Stars} \label{sec:firststars}
The first generations of stars to form in the Universe did so under very different conditions than stars today. As the first stars, by definition, they formed from chemically-pristine material, since no previous generations of stars had existed to enrich the medium with heavy elements. This has long been recognized as a reason that the first stars are likely different than stars today. Without the low-lying electronic transitions common in heavy elements, hydrogen-only gas clouds cannot cool efficiently, as collisions energetic enough to excite atoms from $n=1$ to $n=2$ (which subsequently cool via spontaneous emission of $\Lya$ photons) imply temperatures of $\sim 10^4$ K. Halos with such virial temperatures are not abundant until $z \sim 10$.

However, other cooling channels may be available even in halos too small to support atomic (hydrogen) line cooling. Hydrogen molecules, $\Htwo$, can form using free electrons as a catalyst\footnote{Dust is the primary catalyst of $\Htwo$ formation in the local Universe, but of course is does not exist in the first collapsing clouds.}, 
\begin{align}
	\Hatom + e^- & \rightarrow \Hatom^- + h\nu \\
	\Hatom^- + \Hatom & \rightarrow \Htwo + e^- ,
\end{align}
These reactions are of course limited by the availability of free electrons and the survivability of $H^-$ ions. Exotic models in which an X-ray background emerges before the formation of the first stars may thus affect early star formation by boosting the electron fraction. Even in more conventional scenarios, pristine clouds collapsing at late times may proceed differently than comparable clouds at early times due to the presence of a diffuse X-ray background generated by early HMXBs. 

Even in the absence of astrophysical backgrounds, the formation of $\Htwo$ is limited by the CMB, which at the high redshifts of interest can dissociate the $H^-$ ion. Tegmark et al. 1997 found that the molecular hydrogen fraction in high-$z$ halos scales with the virial temperature as
\begin{equation}
	f_{\Htwo} \approx 3.5 \times 10^{-4} \left(\frac{\Tvir}{10^3 \ \mathrm{K}} \right)^{1.52} .
\end{equation}



Star formation efficiency: unknown.


{\color{red} Note that there are very few studies of PopIII in the 21-cm background.} Can point to Anastasia's stuff, my stuff, maybe Rick's stuff will be done soon...


%%
% PopIII -> PopII via metal enrichment, LW feedback
%%
\subsection{Transition to PopII} \label{sec:PopIII2PopII}
The duration 

Talk about LW feedback, metal enrichment.

\begin{equation}
	M_{\min} = 2.5 \times 10^5 \left(\frac{1+z}{26} \right)^{-3/2} (1 + 6.96(4\pi \JLW)^{0.47})  \ \Msun
\end{equation}
This is from Visbal et al. (2014).


Talk about PopIII.2.





%%
% PopII galaxies via metal enrichment, LW feedback
%%
\subsection{Simple Physical Models for High-$z$ Galaxies} \label{sec:galaxies}




We generally don't resolve galaxies and may not even treat halos (semi-numeric codes operate on density field).


Physical arguments for SFE

Talk about fcoll approach vs. m-dep modeling. 


%%
% Semi-empirical validation of the simple physical arguments
%%
\subsection{Observational Constraints}
Current observations of galaxies at $z > 6$ are consistent with the simple picture of star formation described above. 



%%
% fcoll approach
%%
\subsection{A Fast Alternative}
fcoll approach

{\color{red} Put this at the beginning?? Pitch}



%%%
%% Modeling 
%%%
\section{Predictions for the 21-cm Background} \label{sec:predictions}
Over the last four sections we have assembled a simple physical picture of the IGM at high redshift from which we can derive predictions for the 21-cm brightness temperature. Here, we finally describe the generic sequence of events predicted in most models, and the sensitivity of the 21-cm background to various model parameters of interest. 

%%
% Generic predictions
%%
\subsection{Generic Series of Events}
Figure \ref{fig:predictions} depicts what are now standard predictions for the global 21-cm signal (top) and power spectrum (bottom). Time proceeds from left to right, roughly logarithmically, from the Big Bang until the end of reionization. There are four distinct epochs within this time period, labeled A, B, C, and D, which we describe in more detail below.
\begin{description}
	\item[A. The Dark Ages:] As the Universe expands after cosmological recombination, Compton scattering between free electrons and photons keep the radiation and matter temperature in equilibrium. The density is high enough the collisional coupling remains effective, and so $\TS = \TK = \TCMB$. Eventually, Compton scattering becomes inefficient as the CMB cools and the density continues to fall, which allows the gas to cool faster than the CMB ({\color{red} see also earlier figures}). Collisional coupling remains effective for a short time longer and so $\TK$ follows $\TS$. This results in the first decoupling of $\TS$ from $\TCMB$ at $z \sim 80$, and thus an absorption signature at $\nu \sim 15$ MHz, which comes to an end as collisional coupling becomes inefficient, leaving $\TS$ to reflect $\TCMB$ once again.
	\item[B. First Light:] When the first stars form they flood the IGM with UV photons for the first time. While Lyman continuum photons are trapped near sources, photons with energies $10.2 < h\nu / \mathrm{eV} < 13.6$ either redshift directly through the $\Lya$ resonance or cascade via higher $\Lyn$ levels, giving rise to a large-scale $\Lya$ background capable of triggeiring Wouthuysen-Field coupling as they scatter through the medium. As a result, $\TS$ is driven back toward $\TK$, which (in most models) still reflects the cold temperatures of an adiabatically-cooling IGM.
	\item[C. X-ray Heating:] The first generations of stars beget the first generations of X-ray sources, whether they be the explosions of the first stars themselves or remnant neutron stars or black holes that subsequently accrete. Though the details change depending on the identity of the first X-ray sources, generally such sources provide photons energetic enough to travel great distances. Upon absorption, they heat and partially ionize the gas, eventually driving $\TS > \TCMB$. Once $\TS \gg \TCMB$, the 21-cm signal ``saturates,'' and subsequently sensitive only to the density and ionization fields. However, it is possible that heating is never ``complete'' in this sense before the completion of reionization, meaning neutral pockets of IGM gas may remain at temperatures at or below $\TCMB$ until they are engulfed in the overlap event of large ionized bubbles.
	\item[D. Reionization:] As the global star formation rate density climbs, the growth of ionized regions around groups and clusters of galaxies will continue, eventually culminating in the completion of cosmic reionization. This rise in ionization corresponds to a decline in the amount of neutral hydrogen in the Universe capable of producing or absorbing 21-cm radiation. As a result, the amplitude of the 21-cm signal, both in its mean and fluctuations, falls as reionization progresses.
\end{description}


The evolution of 21-cm fluctuations is more complicated, though this same series of events imprints on fluctuation patterns as well. 


%%
% Parameter studies
%%
\subsection{Sensitivity to Model Parameters}
Use this section to highlight the sensitivity to parameters in more detail.


Things to discuss:
\begin{itemize}
	\item Sensitivity to $\Tmin$ and $\fstar$.
	\item Sensitivity to $\alpha_X$, $E_{\min}$, and $f_X$.
	\item Sensitivity to $\zeta$ and $R_{\mathrm{mfp}}$ (and updates)
	\item Clumping, feedback
	\item Shot noise in galaxy counts in voxels.
	\item PopIII stuff. AGN stuff.
	\item Exotic physics? Defer to Jonathan's chapter?
\end{itemize}

\begin{center}
\begin{table}
\begin{tabular}{||c | c | c||}
\hline
name & description & typical values \\ 
\hline\hline
$\zeta_i$ & Ionizing photon production efficiency & 40 ish  \\ 
\hline
$\zeta_{\alpha}$ & $\Lya$ photon production efficiency & 40 ish  \\ 
\hline
$\zeta_X$ & X-ray photon production efficiency & xxx \\
\hline
$\Tmin$ & Minimum virial temperature of star-forming halos & $10^4$ K \\
\hline
\end{tabular}
\caption{Parameters in simple 21-cm models.}
\end{table}
\end{center}



\subsection{Tools}
Group by codes or techniques? Problem is, not everybody's code is public.
\begin{itemize}
	\item \textsc{21cmFAST} and DexM
	\item \textsc{ares}
	\item Anastasia's code
	\item simfast21
	\item RT simulations
\end{itemize}


\bibliographystyle{plain}
\bibliography{Mirocha/References}


